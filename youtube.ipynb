{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name: Raj KUmar Phagami\n",
    "ID: C0846583\n",
    "Module: 2023@_AML 3204_2 Social Media Analytics\n",
    "Subject: Assignment 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/raj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/raj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/raj/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import os, time\n",
    "import re, json\n",
    "import pandas as pd\n",
    "import threading\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "#import NLP tools\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# importing config.py\n",
    "from config import YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, DEVELOPER_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Youtube Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEYS=[\"AIzaSyC8plwr7LS2a3OEthaGvN-5vNtd9BXAkrQ\",\"AIzaSyBNMIDbVk-cW8uqAqDvkiSJx_n661N8lUM\",\"AIzaSyCvjKBGN20-6ZAnX7MTZOvNs5Q7FyEjtcs\",\"AIzaSyCDbIue93jkyTjXQElbhqh0IpbZFH5lB9g\",\"AIzaSyCLokWAuZ0F2ofGRSxu8Ks41LW-zvS4Eo4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a youtube client\n",
    "youtube_client = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get video data from YouTube API\n",
    "def get_video_data(DEVELOPER_KEY,video_id):\n",
    "    try:\n",
    "        youtube_client = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "        video_response = youtube_client.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "        if len(video_response['items']) == 0:\n",
    "            print(f\"Video not found: {video_id}\")\n",
    "            return []\n",
    "        else:\n",
    "            data = [\n",
    "                video_response['items'][0]['snippet']['description'],\n",
    "                int(video_response['items'][0]['statistics']['viewCount'] if 'viewCount' in video_response['items'][0]['statistics'] else 0),\n",
    "                int(video_response['items'][0]['statistics']['likeCount'] if 'likeCount' in video_response['items'][0]['statistics'] else 0),\n",
    "                int(video_response['items'][0]['statistics']['dislikeCount'] if 'dislikeCount' in video_response['items'][0]['statistics'] else 0),\n",
    "                int(video_response['items'][0]['statistics']['commentCount'] if 'dislikeCount' in video_response['items'][0]['statistics'] else 0),\n",
    "                video_response['items'][0]['contentDetails']['duration'],\n",
    "                int(video_response['items'][0]['statistics']['favoriteCount'])\n",
    "            ]\n",
    "            return data\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        return None\n",
    "    except IndexError:\n",
    "        print(\"Video not found: \",video_id)\n",
    "    \n",
    "# Define function to get video comments from YouTube API\n",
    "def get_video_comments(video_id, max_results=100):\n",
    "    try:\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        while len(comments) < max_results:\n",
    "            comment_response = youtube_client.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "            for item in comment_response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comments.append(comment)\n",
    "            if 'nextPageToken' in comment_response:\n",
    "                next_page_token = comment_response['nextPageToken']\n",
    "            else:\n",
    "                break\n",
    "        return comments\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    \n",
    "# filter the video ids from the dataframe that works with the YouTube API\n",
    "#check if the video id is valid\n",
    "#check connection\n",
    "def check_connection(video_id):\n",
    "    try:\n",
    "        video_response = youtube_client.videos().list(\n",
    "            part=\"snippet,statistics,contentDetails\",\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "        print(f\"Connection successful: {video_id}\")\n",
    "        return True\n",
    "    except HttpError as e:\n",
    "        print(f\"Connection unsuccessful: {video_id}\")\n",
    "        return False\n",
    "    \n",
    "#get the video id ids that works with the YouTube API\n",
    "def filter_video_ids(video_ids):\n",
    "    valid_video_ids = []\n",
    "    for video_id in video_ids:\n",
    "        if check_connection(video_id):\n",
    "            valid_video_ids.append(video_id)\n",
    "    return valid_video_ids\n",
    "\n",
    "# Create a DataFrame from the comments dictionary id and comments\n",
    "def get_comments(filtered_ids, new_columns):\n",
    "    try:\n",
    "        comments = {}\n",
    "        for video in filtered_ids:\n",
    "            comments[video] = get_video_comments(video)\n",
    "        mappped_comments = []\n",
    "        for key, value in comments.items():\n",
    "            if value!=[]:\n",
    "                for comment in value:\n",
    "                    mappped_comments.append([key, comment])\n",
    "        df_comments = pd.DataFrame(mappped_comments, columns=new_columns)\n",
    "        df_comments.to_csv('comments.csv', index=False)\n",
    "        return df_comments\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Get data for each video and store in a list\n",
    "def get_youtube_data(filtered_ids, columns):\n",
    "    video_data_list = []\n",
    "    for index,video in enumerate(filtered_ids):\n",
    "        video_data = get_video_data(video)\n",
    "        if video_data is not None:\n",
    "            video_data_list.append(video_data)\n",
    "        if index == 100:\n",
    "            break\n",
    "    df = pd.DataFrame(video_data_list,columns=columns)\n",
    "    df.to_csv('video_data.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the sentiment score using VADER      \n",
    "def get_sentiment_score(df):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df['polarity_scores'] = df['comments_preprocessed'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "    df['compound'] = df['polarity_scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "    df['sentiment'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "    return df\n",
    "\n",
    "#preprocessing the text data\n",
    "def preprocessing(df):\n",
    "    #lower string   \n",
    "    df['comments_preprocessed'] = df['comments'].str.lower()\n",
    "    #remove punctuation\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].str.replace('[^\\w\\s]','', regex=True)\n",
    "    #remove numbers\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].str.replace('\\d+', '', regex=True)\n",
    "    #remove emojis\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].str.replace('[^\\w\\s#@/:%.,_-]', '', regex=True)\n",
    "    #remove whitespace\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].str.strip()\n",
    "    #tokenize the text using tokenizer\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].apply(lambda x: word_tokenize(x))\n",
    "    #stemming\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].apply(lambda x: [PorterStemmer().stem(y) for y in x])\n",
    "    #remove stopwords\n",
    "    df['comments_preprocessed'] = df['comments_preprocessed'].apply(lambda x: ' '.join([word for word in x if word not in (stopwords.words('english'))]))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of top 10 viewcount videos\n",
    "def get_top_10_viewCount(df):\n",
    "    top_10 = df.sort_values(by='viewCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#list of bottom 10 viewcount videos\n",
    "def get_bottom_10_viewCount(df):\n",
    "    bottom_10 = df.sort_values(by='viewCount', ascending=True).head(10)\n",
    "    return bottom_10\n",
    "\n",
    "#list of top 10 likecount videos\n",
    "def get_top_10_likeCount(df):\n",
    "    top_10 = df.sort_values(by='likeCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#list of bottom 10 likecount videos\n",
    "def get_bottom_10_likeCount(df):\n",
    "    bottom_10 = df.sort_values(by='likeCount', ascending=True).head(10)\n",
    "    return bottom_10\n",
    "\n",
    "#list of top 10 dislikecount videos\n",
    "def get_top_10_dislikeCount(df):\n",
    "    top_10 = df.sort_values(by='dislikeCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#Video with maximum duration\n",
    "def get_max_duration(df):\n",
    "    # df['duration'] = df['duration'].apply(lambda x: pd.to_timedelta(x).total_seconds())\n",
    "    max_duration = df.sort_values(by='duration', ascending=False).head(1)\n",
    "    return max_duration\n",
    "\n",
    "#get statistics\n",
    "def get_stats(df):\n",
    "    #List of top 10pvideos with most views\n",
    "    top_10 = get_top_10_viewCount(df)\n",
    "    print(\"******Top 10 videos with most views******\")\n",
    "    print(top_10.head(10))\n",
    "    \n",
    "    #List of top ten videos with least views\n",
    "    bottom_10 = get_bottom_10_viewCount(df)\n",
    "    print(\"******Bottom 10 videos with least views******\")\n",
    "    print(bottom_10.head(10))\n",
    "    \n",
    "    #List of top 10 videos with most likes\n",
    "    top_10_likes = get_top_10_likeCount(df)\n",
    "    print(\"******Top 10 videos with most likes******\")\n",
    "    print(top_10_likes.head(10))\n",
    "    \n",
    "    #List of bottom 10 with least likes\n",
    "    bottom_10_likes = get_bottom_10_likeCount(df)\n",
    "    print(\"******Bottom 10 videos with least likes******\")\n",
    "    print(bottom_10_likes.head(10))\n",
    "    \n",
    "    #Video with  maximum duration\n",
    "    max_duration = get_max_duration(df)\n",
    "    print(\"******Video with maximum duration******\")\n",
    "    print(max_duration)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (25623, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtubeId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K26_sDKnvMU</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3LPANjHlPxo</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rEnOoWs3FuA</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j9xml1CxgXI</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltwvKLnj1B4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     youtubeId  movieId                               title\n",
       "0  K26_sDKnvMU        1                    Toy Story (1995)\n",
       "1  3LPANjHlPxo        2                      Jumanji (1995)\n",
       "2  rEnOoWs3FuA        3             Grumpier Old Men (1995)\n",
       "3  j9xml1CxgXI        4            Waiting to Exhale (1995)\n",
       "4  ltwvKLnj1B4        5  Father of the Bride Part II (1995)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file into pandas DataFrame\n",
    "df = pd.read_csv('vdoLinks.csv')\n",
    "\n",
    "# Extract video ids\n",
    "print(\"shape\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns we want to extract\n",
    "columns = ['youtubeId','title','description', 'viewCount', 'likeCount', 'dislikeCount', 'commentCount', 'duration', 'favoriteCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_data(columns):\n",
    "    video_data_list = []\n",
    "    for item in df.iterrows():\n",
    "        video_data_list.append(item[1]['youtubeId'])\n",
    "        video_data_list.append(item[1]['title'])\n",
    "        video_data = get_video_data(item[1]['youtubeId'])\n",
    "        if video_data is not None:\n",
    "                video_data_list.append(video_data)\n",
    "    df = pd.DataFrame(video_data_list,columns=columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n",
      "An error occurred: list index out of range\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of top 10 viewcount videos\n",
    "def get_top_10_viewCount(df):\n",
    "    top_10 = df.sort_values(by='viewCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#list of bottom 10 viewcount videos\n",
    "def get_bottom_10_viewCount(df):\n",
    "    bottom_10 = df.sort_values(by='viewCount', ascending=True).head(10)\n",
    "    return bottom_10\n",
    "\n",
    "#list of top 10 likecount videos\n",
    "def get_top_10_likeCount(df):\n",
    "    top_10 = df.sort_values(by='likeCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#list of bottom 10 likecount videos\n",
    "def get_bottom_10_likeCount(df):\n",
    "    bottom_10 = df.sort_values(by='likeCount', ascending=True).head(10)\n",
    "    return bottom_10\n",
    "\n",
    "#list of top 10 dislikecount videos\n",
    "def get_top_10_dislikeCount(df):\n",
    "    top_10 = df.sort_values(by='dislikeCount', ascending=False).head(10)\n",
    "    return top_10\n",
    "\n",
    "#Video with maximum duration\n",
    "def get_max_duration(df):\n",
    "    df['duration'] = df['duration'].apply(lambda x: pd.to_timedelta(x).total_seconds())\n",
    "    max_duration = df.sort_values(by='duration', ascending=False).head(1)\n",
    "    return max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['youtubeId', 'comments']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the comments dictionary id and comments\n",
    "def get_comments():\n",
    "    comments = {}\n",
    "    for video in filtered_ids:\n",
    "        comments[video] = get_video_comments(video)\n",
    "    mappped_comments = []\n",
    "    for key, value in comments.items():\n",
    "        if value!=[]:\n",
    "            for comment in value:\n",
    "                mappped_comments.append([key, comment])\n",
    "    df_comments = pd.DataFrame(mappped_comments, columns=new_columns)\n",
    "    df_comments.to_csv('comments.csv', index=False)\n",
    "    return df_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Read CSV file into pandas DataFrame\n",
    "    df = pd.read_csv('vdoLinks.csv')\n",
    "    # Extract video ids\n",
    "    video_ids = df['youtubeId'].tolist()\n",
    "    df = get_youtube_data()\n",
    "    df_comments = get_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = get_comments()\n",
    "df_comments.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(df_comments)\n",
    "df_comments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtubeId</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_preprocessed</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>polarity_scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dO2LWKpeyI8</td>\n",
       "      <td>He won the world, he lost his own nation.</td>\n",
       "      <td>world lost hi nation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.434, 'neu': 0.566, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dO2LWKpeyI8</td>\n",
       "      <td>2024 biden  the movie by oliver stone lol</td>\n",
       "      <td>biden movi oliv stone lol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'comp...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dO2LWKpeyI8</td>\n",
       "      <td>They hate trump show much biden is tge real di...</td>\n",
       "      <td>hate trump show much biden tge real dirtbag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.346, 'neu': 0.654, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dO2LWKpeyI8</td>\n",
       "      <td>Superb film, get the director&amp;#39;s cut with S...</td>\n",
       "      <td>superb film get director cut sam waterston ad ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.159, 'neu': 0.53, 'pos': 0.311, 'com...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dO2LWKpeyI8</td>\n",
       "      <td>Had to dislike video too many f_cking ads a_sh...</td>\n",
       "      <td>dislik video mani f_cking ad a_shol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     youtubeId                                           comments  \\\n",
       "0  dO2LWKpeyI8          He won the world, he lost his own nation.   \n",
       "1  dO2LWKpeyI8          2024 biden  the movie by oliver stone lol   \n",
       "2  dO2LWKpeyI8  They hate trump show much biden is tge real di...   \n",
       "3  dO2LWKpeyI8  Superb film, get the director&#39;s cut with S...   \n",
       "4  dO2LWKpeyI8  Had to dislike video too many f_cking ads a_sh...   \n",
       "\n",
       "                               comments_preprocessed  sentiments  \\\n",
       "0                               world lost hi nation         0.0   \n",
       "1                          biden movi oliv stone lol         0.0   \n",
       "2        hate trump show much biden tge real dirtbag         0.0   \n",
       "3  superb film get director cut sam waterston ad ...         0.0   \n",
       "4                dislik video mani f_cking ad a_shol         0.0   \n",
       "\n",
       "                                     polarity_scores  compound sentiment  \n",
       "0  {'neg': 0.434, 'neu': 0.566, 'pos': 0.0, 'comp...   -0.3182       neg  \n",
       "1  {'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'comp...    0.4215       pos  \n",
       "2  {'neg': 0.346, 'neu': 0.654, 'pos': 0.0, 'comp...   -0.5719       neg  \n",
       "3  {'neg': 0.159, 'neu': 0.53, 'pos': 0.311, 'com...    0.4588       pos  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000       pos  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_score(df_comments)\n",
    "df_comments.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28a87b76fb28f2adb2db0fbba441a9fe76518d9ac9b633dd3f381cb977c96fcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
